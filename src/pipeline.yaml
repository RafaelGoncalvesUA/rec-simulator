# PIPELINE DEFINITION
# Name: agent-pipeline
# Inputs:
#    batch_file: str
components:
  comp-agent-routine:
    executorLabel: exec-agent-routine
    inputDefinitions:
      artifacts:
        env:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        agent:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-agent-storing:
    executorLabel: exec-agent-storing
    inputDefinitions:
      artifacts:
        agent:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-data-ingestion:
    executorLabel: exec-data-ingestion
    inputDefinitions:
      parameters:
        batch_file:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        dataset_dir:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-data-preparation:
    executorLabel: exec-data-preparation
    inputDefinitions:
      artifacts:
        dataset_dir:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        env:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-agent-routine:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - agent_routine
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef agent_routine(env: Input[Artifact], agent: Output[Model]):\n\
          \    from load_env import load_env_from_dataset\n    from custom_env import\
          \ MicrogridEnv, api_price_function\n    from sb3_agent import SB3Agent\n\
          \n    microgrid = load_env_from_dataset(f\"{env.path}/env.yaml\")\n    environment\
          \ = MicrogridEnv(microgrid, api_price_function)\n\n    agent_instance =\
          \ SB3Agent(\"PPO\", environment)\n    agent_instance.learn(1)\n\n    agent_instance.save(f\"\
          {agent.path}/agent.zip\")\n\n"
        image: rafego16/pipeline-custom-image-train:latest
    exec-agent-storing:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - agent_storing
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'minio' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef agent_storing(agent: Input[Model]):\n    from minio import Minio\n\
          \    from dotenv import load_dotenv\n    import os\n\n    load_dotenv(dotenv_path=\"\
          /app/.env\")\n\n    minio_client = Minio(\n        endpoint=os.getenv(\"\
          MINIO_ENDPOINT\"),\n        access_key=os.getenv(\"MINIO_ACCESS_KEY\"),\n\
          \        secret_key=os.getenv(\"MINIO_SECRET_KEY\"),\n        secure=False,\n\
          \    )\n\n    # create a new bucket called 'agents'\n    if not minio_client.bucket_exists(\"\
          agents\"):\n        minio_client.make_bucket(\"agents\")\n\n    # upload\
          \ the agent to the 'agents' bucket\n    minio_client.fput_object(\n    \
          \    \"agents\",\n        agent.path.split(\"/\")[-1],\n        f\"{agent.path}/agent.zip\"\
          ,\n    )\n\n    print(f\"Agent {agent.path.split('/')[-1]} uploaded to MinIO.\"\
          )\n\n    # TODO: notify inference service\n\n"
        image: rafego16/pipeline-custom-image:latest
    exec-data-ingestion:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - data_ingestion
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'minio' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef data_ingestion(batch_file: str, dataset_dir: Output[Artifact]):\n\
          \    from minio import Minio\n    import pandas as pd\n    from dotenv import\
          \ load_dotenv\n    import os\n\n    load_dotenv(dotenv_path=\"/app/.env\"\
          )\n\n    minio_client = Minio(\n        endpoint=os.getenv(\"MINIO_ENDPOINT\"\
          ),\n        access_key=os.getenv(\"MINIO_ACCESS_KEY\"),\n        secret_key=os.getenv(\"\
          MINIO_SECRET_KEY\"),\n        secure=False,\n    )\n\n    # retrieve batch\
          \ file from MinIO's specified bucket\n    minio_client.fget_object(os.getenv(\"\
          MINIO_BUCKET\"), batch_file, \"batch.json\")\n\n    os.makedirs(f\"{dataset_dir.path}/grid\"\
          , exist_ok=True)\n    os.makedirs(f\"{dataset_dir.path}/loads\", exist_ok=True)\n\
          \    os.makedirs(f\"{dataset_dir.path}/renewables\", exist_ok=True)\n\n\
          \    df = pd.read_json(\"batch.json\")\n    ids = df[\"id\"].unique()\n\n\
          \    for module in ids:\n        if module.startswith(\"grid\"):\n     \
          \       df[df[\"id\"] == module][[\"g0\", \"g1\", \"g2\", \"g3\"]].to_csv(\n\
          \                f\"{dataset_dir.path}/grid/{module}.csv\"\n           \
          \ )\n        elif module.startswith(\"load\"):\n            df[df[\"id\"\
          ] == module][\"l0\"].to_csv(\n                f\"{dataset_dir.path}/loads/{module}.csv\"\
          \n            )\n        elif module.startswith(\"renewable\"):\n      \
          \      df[df[\"id\"] == module][\"r0\"].to_csv(\n                f\"{dataset_dir.path}/renewables/{module}.csv\"\
          \n            )\n\n"
        image: rafego16/pipeline-custom-image:latest
    exec-data-preparation:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - data_preparation
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef data_preparation(dataset_dir: Input[Artifact], env: Output[Artifact]):\n\
          \    from pymgrid import Microgrid\n    from pymgrid.modules import BatteryModule,\
          \ LoadModule, RenewableModule, GridModule\n    import yaml\n    import pandas\
          \ as pd\n    import os\n\n    grids = []\n    loads = []\n    renewables\
          \ = []\n\n    config = yaml.safe_load(open(\"config.yaml\", 'r'))\n\n  \
          \  for module in ['grid', 'loads', 'renewables']:\n        if os.path.exists(os.path.join(dataset_dir.path,\
          \ module)):\n            for filename in os.listdir(os.path.join(dataset_dir.path,\
          \ module)):\n                ts = pd.read_csv(os.path.join(dataset_dir.path,\
          \ module, filename), index_col=0)\n\n                if module == 'grid':\n\
          \                    grids.append(\n                        GridModule(\n\
          \                            max_export=config['max_export'],\n        \
          \                    max_import=config['max_import'],\n                \
          \            time_series=ts,\n                        )\n              \
          \      )\n\n                if module == 'loads':\n                    loads.append(\n\
          \                        LoadModule(time_series=ts)\n                  \
          \  )\n\n                elif module == 'renewables':\n                 \
          \   src_type = filename.split('_')[0]\n\n                    renewables.append(\n\
          \                        (src_type, RenewableModule(time_series=ts))\n \
          \                   )\n        else:\n            print(f'{module} directory\
          \ not found. Exiting...')\n            exit(1)\n\n\n    batteries = [\n\
          \        BatteryModule(**b)\n        for b in yaml.safe_load(open(\"battery.yaml\"\
          , 'r')).values()\n    ]\n\n    microgrid = Microgrid([*batteries, *renewables,\
          \ *loads, *grids])\n\n    os.makedirs(env.path, exist_ok=True)\n    microgrid.dump(open(os.path.join(env.path,\
          \ 'env.yaml'), 'w'))\n\n    print(f'Microgrid saved to {env.path}')\n\n"
        image: rafego16/pipeline-custom-image:latest
pipelineInfo:
  name: agent-pipeline
root:
  dag:
    tasks:
      agent-routine:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-agent-routine
        dependentTasks:
        - data-preparation
        inputs:
          artifacts:
            env:
              taskOutputArtifact:
                outputArtifactKey: env
                producerTask: data-preparation
        taskInfo:
          name: agent-routine
      agent-storing:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-agent-storing
        dependentTasks:
        - agent-routine
        inputs:
          artifacts:
            agent:
              taskOutputArtifact:
                outputArtifactKey: agent
                producerTask: agent-routine
        taskInfo:
          name: agent-storing
      data-ingestion:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-ingestion
        inputs:
          parameters:
            batch_file:
              componentInputParameter: batch_file
        taskInfo:
          name: data-ingestion
      data-preparation:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-preparation
        dependentTasks:
        - data-ingestion
        inputs:
          artifacts:
            dataset_dir:
              taskOutputArtifact:
                outputArtifactKey: dataset_dir
                producerTask: data-ingestion
        taskInfo:
          name: data-preparation
  inputDefinitions:
    parameters:
      batch_file:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0
